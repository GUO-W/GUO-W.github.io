---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Ph.D. student at INRIA [RobotLearn team](https://team.inria.fr/robotlear) (former Perception team) and IRI, supervised by [Dr.Xavier Alameda-Pineda](http://xavirema.eu/) and [Dr.Francesc Moreno-Noguer](http://www.iri.upc.edu/people/fmoreno/). 

Before that I got bachelor and master degree from Beihang University, and double degree from CentraleSupélec.

## News  
**03/2022** Our paper "Multi-Person Extreme Motion Prediction" accepted at CVPR2022.  
**10/2021** [ExPI Dataset](https://team.inria.fr/robotlearn/multi-person-extreme-motion-prediction) released.  
**10/2021** We win [UVO Open-World Segmentation Challenge 2021](https://sites.google.com/view/unidentified-video-object/home) (2/2 awards), technical reports: [Track-1](https://arxiv.org/abs/2110.10239) and [Track-2](https://arxiv.org/abs/2110.11661).  
**07/2021** Present on poster session of PAISS summer school.  
**01/2021** Our paper "PI-Net: Pose Interacting Network for Multi-Person Monocular 3D Pose Estimation" accepted at WACV2021.  
**10/2020** Present on ACM MM'20 Doctoral Symposium.   

## Publications
<style>
* {
  box-sizing: border-box;
}

/* Create two unequal columns that floats next to each other */
.column {
  float: left;
  padding: 0px;
}

.left {
  align-items: top;
  width: 30%;
}

.right {
  align-items: top;
  width: 68%;
}

.middle {
  align-items: top;
  width: 2%;
}
/* Clear floats after the columns */
.row:after {
  content: "";
  align-items: top;
  display: table;
  clear: both;
}

.content figure {
       width: 90%;
       display: flex;
       align-items: top;
       overflow: hidden;
       margin-left: auto!important;
       margin-right: auto!important;
      }
</style>

Here is a selection of recent publications, full list can be found on [Google Scholar](https://scholar.google.com/citations?user=1fkvaz4AAAAJ&hl=fr).

<!-- 2022 arXiv BackToMLP-->
<article class="row">
  <div class="column left">
    <figure class="image">
      <img src="../images/2022-BackToMLP.png" width="100%">
    </figure>
  </div>
  <div class="column middle">
    <figure class="image">
      <img src="../images/blank_placeholder.png" width="100%">
    </figure>
  </div>
  <div class="column right">
    <div class="content">
      <p>
        <b>Back to MLP: A Simple Baseline for Human Motion Prediction</b><br>
        <b>Wen Guo*</b>, Yuming Du*, Xi Shen, Vincent Lepetit, Xavier Alameda-Pineda, Francesc Moreno-Noguer<br>
        <i>arXiv preprint arXiv:2207.01567</i><br>
        <a href="https://arxiv.org/abs/2207.01567" target="_blank">[paper]</a>
        <a href="https://dulucas.github.io/Homepage/sbmotion/" target="_blank">[project page]</a>
        <a href="https://github.com/dulucas/siMLPe" target="_blank">[Code]</a>
      </p>
    </div>
  </div>
</article>

<!-- 2022 arXiv HiT DVAE-->
<article class="row">
  <div class="column left">
    <figure class="image">
      <img src="../images/2022-HiT-DVAE.png" width="100%">
    </figure>
  </div>
  <div class="column middle">
    <figure class="image">
      <img src="../images/blank_placeholder.png" width="100%">
    </figure>
  </div>
  <div class="column right">
    <div class="content">
      <p>
        <b>HiT-DVAE: Human Motion Generation via Hierarchical Transformer Dynamical VAE</b><br>
        Xiaoyu BIE*, <b>Wen Guo*</b>, Simon Leglaive, Laurent Girin, Francesc Moreno-Noguer, Xavier Alameda-Pineda<br>
        <i>arXiv preprint arXiv:2204.01565</i><br>
        <a href="https://arxiv.org/abs/2204.01565" target="_blank">[paper]</a>
        [Code]
      </p>
    </div>
  </div>
</article>

<!-- 2022 cvpr ExPI-->
<article class="row">

  <div class="column left">
    <figure class="image">
      <img src="../images/2022-xia-res.png" width="100%">
    </figure>
  </div>
  <div class="column middle">
    <figure class="image">
      <img src="../images/blank_placeholder.png" width="100%">
    </figure>
  </div>

  <div class="column right">
    <div class="content">
      <p>
        <b>Multi-Person Extreme Motion Prediction</b><br>
        <b>Wen Guo</b>*, Xiaoyu BIE*, Xavier Alameda-Pineda, Francesc Moreno<br>
        <i>CVPR2022</i><br>
        <a href="https://arxiv.org/abs/2105.08825" target="_blank">[Paper]</a>
        <a href="https://team.inria.fr/robotlearn/multi-person-extreme-motion-prediction" target="_blank">[Project page]</a>
        <a href="https://github.com/GUO-W/MultiMotion" target="_blank">[Code]</a> 
	<a href="https://zenodo.org/record/5578329#.YbjaLPHMK3J" target="_blank">[Dataset]</a>
      </p>
    </div>
  </div>
</article>

<!-- 2021 wacv pi-net-->
<article class="row">
  <div class="column left">
    <figure class="image">
      <img src="../images/2021-pi-net.png" width="100%">
    </figure>
  </div>
  <div class="column middle">
    <figure class="image">
      <img src="../images/blank_placeholder.png" width="100%">
    </figure>
  </div>
  <div class="column right">
    <div class="content">
      <p>
        <b>PI-Net: Pose Interacting Network for Multi-Person Monocular 3D Pose Estimation</b><br>
	      <b>Wen Guo</b>, Enric Corona, Francesc Moreno-Noguer, Xavier Alameda-Pineda<br>
        <i>WACV2021.</i><br>
        <a href="https://openaccess.thecvf.com/content/WACV2021/papers/Guo_PI-Net_Pose_Interacting_Network_for_Multi-Person_Monocular_3D_Pose_Estimation_WACV_2021_paper.pdf" target="_blank">[Paper]</a>
        <a href="https://team.inria.fr/robotlearn/pi-net-pose-interacting-network-for-multi-person-monocular-3d-pose-estimation/" target="_blank">[Project page]</a>
        <a href="https://github.com/GUO-W/PI-Net" target="_blank">[Code]</a>
      </p>
    </div>
  </div>
</article>

<!-- 2020 acm mm ds-->
<article class="row">
  <div class="column left">
    <figure class="image">
      <img src="../images/2021-ACMMM.png" width="100%">
    </figure>
  </div>
  <div class="column middle">
    <figure class="image">
      <img src="../images/blank_placeholder.png" width="100%">
    </figure>
  </div>
  <div class="column right">
    <div class="content">
      <p>
        <b>Multi-person Pose Estimation in Complex Physical Interactions</b><br>
	      <b>Wen Guo</b><br>
        <i>In Proceedings of the 28th ACM International Conference on Multimedia (MM ’20). Association for Computing Machinery, New York, NY, USA, 4752–4755. DOI:https://doi.org/10.1145/3394171.3416519 (DS) </i><br>
        <a href="https://dl.acm.org/doi/10.1145/3394171.3416519" target="_blank">[Paper]</a>
      </p>
    </div>
  </div>
</article>


## Datasets
<!-- 2021 dataset ExPI-->
<article class="row">

  <div class="column left">
    <figure class="image">
      <img src="../images/expi.png" width="100%">
    </figure>
  </div>
  <div class="column middle">
    <figure class="image">
      <img src="../images/blank_placeholder.png" width="100%">
    </figure>
  </div>
  <div class="column right">
    <div class="content">
      <p>
        <b>Extreme Pose Interaction (ExPI) Dataset</b><br>
        <a href="https://team.inria.fr/robotlearn/multi-person-extreme-motion-prediction" target="_blank">[Dataset]</a><br>
	It contains 115 sequences of exteme Lindy Hop poses, with 3D MoCap data (annotated from 20 mocap cameras and manual clean), multi-view images (68 views) and 3D shapes as texured meshes. Welcome to download the <a href="https://zenodo.org/record/5578329#.Ymv4R_VBy3J" target="_blank">[Data]</a>.<br>
      </p>
    </div>
  </div>
</article>

## Services
Reviewing for ACM MM'20-21, IJCV, ICPR'21, WACV'21, ACM TOMM.

## Contact
wen[dot]guo[at]inria[dot]fr


